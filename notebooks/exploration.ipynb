{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect-Based Sentiment Analysis Exploration\n",
    "\n",
    "This notebook demonstrates the exploration and testing of different ABSA implementations.\n",
    "\n",
    "## Overview\n",
    "- **Lexicon-based ABSA**: Using spaCy and sentiment lexicons\n",
    "- **Transformer-based ABSA**: Using pre-trained Hugging Face models\n",
    "- **LLM-based ABSA**: Using local LLM through Ollama\n",
    "\n",
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:21:55.950135Z",
     "start_time": "2025-10-23T12:21:52.436257Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "from src.base import AspectSentiment\n",
    "from src.lexicon_absa import LexiconABSA\n",
    "from src.transformer_absa import TransformerABSA\n",
    "from src.llm_absa import LLMABSA\n",
    "from src.utils import (\n",
    "    load_test_data, save_results, calculate_accuracy, \n",
    "    calculate_precision_recall_f1, benchmark_analyzer,\n",
    "    create_sample_data, print_analysis_results, ensure_data_directory\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Analyzers\n",
    "\n",
    "Let's initialize all three ABSA implementations:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:21:59.641313Z",
     "start_time": "2025-10-23T12:21:57.594205Z"
    }
   },
   "source": [
    "analyzers = {}\n",
    "results = {}\n",
    "\n",
    "print(\"Initializing analyzers...\")\n",
    "\n",
    "try:\n",
    "    lexicon_analyzer = LexiconABSA()\n",
    "    analyzers['Lexicon'] = lexicon_analyzer\n",
    "    print(\"✓ LexiconABSA initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ LexiconABSA failed to initialize: {e}\")\n",
    "\n",
    "try:\n",
    "    transformer_analyzer = TransformerABSA()\n",
    "    analyzers['Transformer'] = transformer_analyzer\n",
    "    print(\"✓ TransformerABSA initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ TransformerABSA failed to initialize: {e}\")\n",
    "\n",
    "try:\n",
    "    llm_analyzer = LLMABSA()\n",
    "    analyzers['LLM'] = llm_analyzer\n",
    "    print(\"✓ LLMABSA initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ LLMABSA failed to initialize: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully initialized {len(analyzers)} analyzers\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing analyzers...\n",
      "✓ LexiconABSA initialized successfully\n",
      "Error loading model yangheng/deberta-v3-base-absa-v1.1: \n",
      "DebertaV2Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "Falling back to alternative ABSA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TransformerABSA initialized successfully\n",
      "✓ LLMABSA initialized successfully\n",
      "\n",
      "Successfully initialized 3 analyzers\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n",
    "\n",
    "Let's load our test data and create sample data if needed:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:22:02.185064Z",
     "start_time": "2025-10-23T12:22:02.180357Z"
    }
   },
   "source": [
    "data_file = ensure_data_directory()\n",
    "test_data = load_test_data(data_file)\n",
    "\n",
    "if not test_data:\n",
    "    print(\"Creating sample test data...\")\n",
    "    test_data = create_sample_data()\n",
    "    save_results(test_data, data_file)\n",
    "\n",
    "print(f\"Loaded {len(test_data)} test samples\")\n",
    "print(\"\\nSample test data:\")\n",
    "for i, item in enumerate(test_data[:3]):\n",
    "    aspects = [f\"{a['aspect']} ({a['sentiment']})\" for a in item['ground_truth']]\n",
    "    print(f\"{i+1}. {item['text']}\")\n",
    "    print(f\"   Expected: {aspects}\")\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 test samples\n",
      "\n",
      "Sample test data:\n",
      "1. The pizza was delicious but the service was terrible.\n",
      "   Expected: ['pizza (positive)', 'service (negative)']\n",
      "\n",
      "2. The laptop has great performance and excellent battery life.\n",
      "   Expected: ['performance (positive)', 'battery life (positive)']\n",
      "\n",
      "3. The hotel room was clean and comfortable, but the WiFi was slow.\n",
      "   Expected: ['hotel room (positive)', 'WiFi (negative)']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Testing\n",
    "\n",
    "Let's test each analyzer individually on sample texts:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:23:02.445909Z",
     "start_time": "2025-10-23T12:22:24.095819Z"
    }
   },
   "source": [
    "test_texts = [\n",
    "    \"The pizza was delicious but the service was terrible.\",\n",
    "    \"The laptop has great performance and excellent battery life.\",\n",
    "    \"The hotel room was clean and comfortable, but the WiFi was slow.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for name, analyzer in analyzers.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            results = analyzer.analyze(text)\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            print(f\"\\n{name} Results ({processing_time:.3f}s):\")\n",
    "            if results:\n",
    "                for result in results:\n",
    "                    print(f\"  - {result.aspect}: {result.sentiment} (confidence: {result.confidence:.3f})\")\n",
    "            else:\n",
    "                print(\"  No aspects found\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n{name} Error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: The pizza was delicious but the service was terrible.\n",
      "--------------------------------------------------\n",
      "\n",
      "Lexicon Results (0.007s):\n",
      "  - pizza: positive (confidence: 0.572)\n",
      "  - service: positive (confidence: 0.572)\n",
      "  - the pizza: positive (confidence: 0.572)\n",
      "  - the service: positive (confidence: 0.572)\n",
      "\n",
      "Transformer Results (0.111s):\n",
      "  - pizza: positive (confidence: 0.953)\n",
      "  - service: negative (confidence: 0.901)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Results (16.964s):\n",
      "  - pizza: positive (confidence: 0.900)\n",
      "  - service: negative (confidence: 0.800)\n",
      "\n",
      "Text: The laptop has great performance and excellent battery life.\n",
      "--------------------------------------------------\n",
      "\n",
      "Lexicon Results (0.045s):\n",
      "  - laptop: positive (confidence: 0.625)\n",
      "  - performance: positive (confidence: 0.625)\n",
      "  - battery: positive (confidence: 0.625)\n",
      "  - life: positive (confidence: 0.625)\n",
      "  - the laptop: positive (confidence: 0.625)\n",
      "  - great performance: positive (confidence: 0.625)\n",
      "  - excellent battery life: positive (confidence: 0.625)\n",
      "\n",
      "Transformer Results (1.010s):\n",
      "  - life: positive (confidence: 0.986)\n",
      "  - battery: positive (confidence: 0.972)\n",
      "  - laptop: positive (confidence: 0.986)\n",
      "  - performance: positive (confidence: 0.986)\n",
      "  - excellent battery life: positive (confidence: 0.983)\n",
      "  - great performance: positive (confidence: 0.986)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Results (9.617s):\n",
      "  - performance: positive (confidence: 0.900)\n",
      "  - battery life: positive (confidence: 0.800)\n",
      "\n",
      "Text: The hotel room was clean and comfortable, but the WiFi was slow.\n",
      "--------------------------------------------------\n",
      "\n",
      "Lexicon Results (0.019s):\n",
      "  - hotel: positive (confidence: 0.511)\n",
      "  - room: positive (confidence: 0.511)\n",
      "  - wifi: positive (confidence: 0.511)\n",
      "  - the hotel room: positive (confidence: 0.511)\n",
      "  - the wifi: positive (confidence: 0.511)\n",
      "\n",
      "Transformer Results (0.220s):\n",
      "  - room: positive (confidence: 0.591)\n",
      "  - hotel: positive (confidence: 0.925)\n",
      "  - wifi: neutral (confidence: 0.472)\n",
      "\n",
      "LLM Results (10.342s):\n",
      "  - cleanliness: positive (confidence: 0.900)\n",
      "  - comfort: positive (confidence: 0.800)\n",
      "  - WiFi speed: negative (confidence: 0.700)\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
